{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    "from tqdm import tqdm\r\n",
    "import nltk\r\n",
    "from nltk import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "nltk.download('stopwords')\r\n",
    "stop_words = stopwords.words('english')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pranav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "from keras.models import sequential\r\n",
    "from keras.layers.recurrent import LSTM,GRU\r\n",
    "from keras.layers.core import Dense,Dropout,Activation\r\n",
    "from keras.layers.embeddings import Embedding\r\n",
    "from keras.layers.normalization import BatchNormalization\r\n",
    "from keras.utils import np_utils\r\n",
    "from sklearn import preprocessing,decomposition,model_selection,metrics,pipeline,feature_extraction\r\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV, train_test_split\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\r\n",
    "from sklearn.decomposition import TruncatedSVD\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "train = pd.read_csv(\"train.csv\")\r\n",
    "test = pd.read_csv(\"test.csv\")\r\n",
    "sub = pd.read_csv(\"sample_submission.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "train.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, train.target.values, \r\n",
    "                                                  stratify=train.target.values, \r\n",
    "                                                  random_state=42, \r\n",
    "                                                  test_size=0.1, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# Always start with these features. They work (almost) everytime!\r\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \r\n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\r\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\r\n",
    "            stop_words = 'english')\r\n",
    "\r\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\r\n",
    "def tfidf(data):\r\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=3,  max_features=None, \r\n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\r\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\r\n",
    "            stop_words = 'english')\r\n",
    "\r\n",
    "    train = tfidf_vectorizer.fit_transform(data)\r\n",
    "\r\n",
    "    return train, tfidf_vectorizer\r\n",
    "\r\n",
    "xtrain_tfidf, tfidf_vectorizer = tfidf(xtrain)\r\n",
    "xvalid_tfidf = tfidf_vectorizer.transform(xvalid)\r\n",
    "pickle.dump(tfidf_vectorizer, open(\"tfidf1.pkl\", \"wb\"))\r\n",
    "\r\n",
    "\r\n",
    "#tfv.fit(list(xtrain) + list(xvalid))\r\n",
    "#xtrain_tfv =  tfv.transform(xtrain) \r\n",
    "#xvalid_tfv = tfv.transform(xvalid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "clf = LogisticRegression(C=1.0)\r\n",
    "clf.fit(xtrain_tfidf, ytrain)\r\n",
    "predictions = clf.predict(xvalid_tfidf)\r\n",
    "print(\"f1 score : {}\".format(f1_score(yvalid,predictions)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1 score : 0.7636363636363637\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "predictions.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(762,)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Trying another model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# Count Vectorizer\r\n",
    "\r\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\r\n",
    "\r\n",
    "## let's get counts for the first 5 tweets in the data\r\n",
    "example_train_vectors = count_vectorizer.fit_transform(train[\"text\"][0:5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "print(example_train_vectors[0].todense().shape)\r\n",
    "print(example_train_vectors[0].todense())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train[\"text\"])\r\n",
    "\r\n",
    "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\r\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - \r\n",
    "# i.e. that the train and test vectors use the same set of tokens.\r\n",
    "test_vectors = count_vectorizer.transform(test[\"text\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "clf = RidgeClassifier()\r\n",
    "#LogisticRegression(C = 1)\r\n",
    "scores = model_selection.cross_val_score(clf, train_vectors, train[\"target\"], cv=3, scoring=\"f1\")\r\n",
    "scores\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.59421842, 0.56455572, 0.64149093])"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "clf.fit(train_vectors, train[\"target\"])\r\n",
    "sub[\"target\"] = clf.predict(test_vectors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "sub.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "sub.to_csv(\"sub1.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7eb19f74f7a13054a7c1a3732ca46800bac79a34584c29b7976e602a9120cea3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}